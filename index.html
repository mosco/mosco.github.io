<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Amit Moscovich - Academic homepage</title>

    <!-- Bootstrap Core CSS -->
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="vendor/font-awesome/css/academicons.css"/>
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">

    <!-- Theme CSS -->
    <link href="css/grayscale.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <i class="fa fa-play-circle"></i> <span class="light">Home</span>
                </a>
            </div>
 
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#geodesicnn">Geodesic NN</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#exactbj">Berk-Jones</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#crossprob">Boundary crossing</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#forestdensity">Forest density</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Amit Moscovich</h1>
                        <p class="intro-text">Academic homepage</p>
                        <a href="#about" class="btn btn-circle page-scroll">
                            <i class="fa fa-angle-double-down animated"></i>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">

                <h1 name="about">About</h1>

                <div>
                    <p>
                    I am currently a postdoc at <a href="https://www.tau.ac.il">Tel Aviv University's</a> <a href="https://en-exact-sciences.tau.ac.il/math/Statistics-and-Operations%20Research-profile">department of statistics</a>, working with <a href="http://www.tau.ac.il/~saharon/">Prof. Saharon Rosset</a> on various aspects of cross-validation.
                        I did my Ph.D. at the department of <a href="https://www.weizmann.ac.il/math/">Computer Science and Applied Mathematics</a>
                        at the <a href="https://www.weizmann.ac.il/">Weizmann Institute of Science</a> in Israel,
                        where <a href="http://www.wisdom.weizmann.ac.il/~/nadler/">Prof. Boaz Nadler</a> was my doctoral advisor.
                    </p>
                    <p>
                        My research interests include statistical machine learning and various aspects of computational and mathematical statistics.
                    </p>
                    <p>Office 418, Kaplun building, Tel Aviv University, Israel.</p>
                </div>
                <div style="float: left; width: 50%">
                    <img src="img/me_and_avigail.jpg" class="img-rounded" style="width: 66%; height: auto; margin-left: auto; margin-right: auto; display: block"><br><br>
                </div>
                <div style="float: right; width: 50%">
                    <ul class="list-inline banner-social-buttons" style="float: left; width: 40%">
                        <li>
                            <a href="mailto:moscovich@gmail.com" class="btn btn-default btn-lg"><i class="fa fa-envelope-square fa-fw"></i> <span class="network-name">email</span></a>
                        </li>
                        <li>
                            <a href="https://scholar.google.co.il/citations?user=978bqAwAAAAJ" class="btn btn-default btn-lg"><i class="ai ai-google-scholar-square"></i> <span class="network-name">Scholar</span></a>
                        </li>
                        <li>
                            <a href="https://www.researchgate.net/profile/Amit_Moscovich" class="btn btn-default btn-lg"><i class="ai ai-researchgate-square"></i> <span class="network-name">Research Gate</span></a>
                        </li>
                        <li>
                            <a href="https://github.com/mosco" class="btn btn-default btn-lg"><i class="fa fa-github fa-fw"></i> <span class="network-name">Github</span></a>
                        </li>
                        <li>
                            <a href="https://stackexchange.com/users/22879/amit-moscovich" class="btn btn-default btn-lg"><i class="fa fa-stack-exchange fa-fw"></i> <span class="network-name">Stack Exchange</span></a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/amit.moscovich.9" class="btn btn-default btn-lg"><i class="fa fa-facebook-official fa-fw"></i> <span class="network-name">Facebook</span></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <section id="download" class="content-section text-center">
        <div class="transition-section">
            <div class="container">
                <div class="col-lg-8 col-lg-offset-2">
                    <br>
                    <br>
                    <br>
                    <h1>Research projects</h1>
                </div>
            </div>
        </div>
    </section>

    <section id="geodesicnn" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h1 name="exactbj">Geodesic nearest neighbors</h1>
                <p>
                Consider nonparametric regression (e.g. <a href="https://en.wikipedia.org/wiki/Kernel_regression">Nadaraya-Watson</a>) in a high-dimensional metric space. In the general case, this typically requires an unreasonable number of labeled points due to the curse of dimensionality.
                We make two simplifying assumptions:
                    <ul>
                        <li><p><b>Manifold assumption:</b> The data points are supported on (or near) a low-dimensional manifold.</p></li>
                        <li><p><b>Semi-supervised data set:</b> In addition to the labeled points, we are given a <b>large</b> sample of unlabeled points</p></li>
                    </ul>
                </p>
                <p>
                    If there are many unlabeled points, then we can use them to estimate geodesic distances along the (unknown) manifold.
                    This is done by connecting pairs of close points by a weighted edge with weight equal to their euclidean distance.
                    Geodesic distances in the resulting graph approximate geodesic distances in the manifold.
                    We propose to use this idea to apply standard nonparametric methods, but using the manifold distances instead of the euclidean distances. Thereby avoiding the curse of dimensionality.
                </p>
                <img src="img/isomap.jpg" class="img-rounded" style="margin-left: auto; margin-right: auto; display: block">
                <p style="text-align: center">
                    <small>Figure shamelessly stolen from <a href="http://isomap.stanford.edu/">IsoMap homepage</a></small>
                </p>
                <p>
                    One way to think about manifold/graph-based semi-supervised methods, is to consider their Euclidean analogues.
                    Consider the following table:
                </p>

                <table class="table">
                    <thead>
                        <tr>
                            <th>Nonparametric regression method</th>
                            <th>Analogous approach for graphs/manifolds</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Regression using orthogonal functions</td>
                            <td><a href="https://stuff.mit.edu/afs/athena/course/9/9.520/www/spring08/Papers/Belkin-ML-04.pdf">Laplacian eigenvector regression</a></td>
                        </tr>
                        <tr>
                            <td>Wavelet regression</td>
                            <td><a href="https://web.stanford.edu/~gavish/documents/Haarlike_ICML_2010.pdf">Graph multiscale wavelet regression</a></td>
                        </tr>
                        <tr>
                            <td>Nadaraya-Watson / K-nearest neighbor</td>
                            <td><b>Geodesic nearest-neighbor</b></td>
                        </tr>
                    </tbody>
                </table>

                <p>
                    K nearest-neighbors and Nadaraya-watson regression are fundamental nonparametric regression method, but their manifold analogues have barely been studied.
                    This was the initial motivation for this project. Results:
                </p>
                <h4> Key results </h4>
                <p>
                    <ul>
                        <li><p><b>Minimax optimality:</b> given a sufficient number of unlabeled data points from an unknown manifold, the geodesic K nearest-neighbors regressor obtains the finite-sample minimax bound for a Lipschitz function on the manifold, as if it were completely specified.</p></li>
                        <li><p><b>Good performance:</b> on manifold-structured signals.
                        <li><p><b>Efficient computation:</b> regression and classification methods based on geodesic nearest neighbors can be efficiently computed, both for the transductive and the inductive cases of semi-supervised learning.
                    </ul>
                </p>
                <h4> Documents </h4>
                <p>
                    This paper presents a new algorithm that efficiently finds the k nearest labeled vertices for all vertices in the graph.
                    We combine this algorithm with the ideas above to a problem of semi-supervised indoor localization using WiFi fingerprints.
                </p>
                <p>
                Amit Moscovich, Ariel Jaffe, Boaz Nadler <a href="https://arxiv.org/abs/1611.02221"><b>Minimax-optimal semi-supervised regression on unknown manifolds</b></a>, AISTATS (2017).
                </p>
                <p>
                Amit Moscovich, Ariel Jaffe, Boaz Nadler <a href="geodesic-knn/Minimax-optimal semi-supervised regression on unknown manifolds poster.pdf"><b>Minimax-optimal semi-supervised regression on unknown manifolds</b></a>, poster presentation at AISTATS (2017).
                </p>
                <p>
                Amit Moscovich, Ariel Jaffe, Boaz Nadler <a href="geodesic-knn/geodesic-knn-slides-8.pdf"><b>Semi-supervised regression on unknown manifolds</b></a>, presented at the Princeton applied math department, Hebrew university learning club and statistics seminar, Tel-Aviv university statistics seminar and the Ben-Gurion CS seminar.
                </p>
                <img src="img/real_data_floor.png" class="img-rounded" style="width: 41.5%; margin-left: auto; margin-right: auto;">
                <img src="img/SimEnvironment.png" class="img-rounded" style="width: 52%; margin-left: auto; margin-right: auto;">
                <br>
                <br>
                <br>
                <br>
                <h4> Code </h4>
                <p>
                    Code for efficiently finding K-nearest-labeled vertices:
                    <a href="https://github.com/mosco/geodesic-knn">Python</a>
                </p>
            </div>
        </div>
    </section>
    <section id="exactbj" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h1 name="exactbj">The exact Berk-Jones statistics</h1>
                <p>
                This study started with an idea to modify the <a href="https://projecteuclid.org/euclid.aos/1085408492">Higher Criticism statistic</a> so as to improve its finite-sample behavior. After a lot of digging, this turned out to be a rediscovery of the M<sub>n</sub> goodness-of-fit statistic proposed by <a href="https://link.springer.com/article/10.1007/BF00533250">Berk and Jones in 1979</a>.
                <p>
                    In this work we present a new derivation of the exact Berk-Jones statistics, prove that they are asymptotically optimal for the detection of Sparse Mixtures and consistent. We also compare them to other goodness-of-fit statistics and present an efficient method to compute the p-values of the one-sided statistics.
                </p>
                <p>
                    Overall, I believe these results demonstrate that the exact Berk-Jones statistics are an interesting alternative to other goodness-of-fit statistics such as <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov-Smirnov</a> and <a href="https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test">Anderson-Darling</a>, despite having received (much) less attention. They are particularly suited for the detection of alternatives that differ from the null hypothesis at the tails of the distribution. </p>
                <h4> Documents </h4>
                <p>
                Amit Moscovich, Boaz Nadler, Clifford Spiegelman <a href="https://doi.org/10.1214/16-EJS1172"><b>On the exact Berk-Jones statistics and their p-value calculation</b></a>, Electronic Journal of Statistics (2016). <a href="http://doi.org/10.1214/16-EJS1172SUPP">(Supplementary material)</a> <br>
                </p>
                <p>
                    Amit Moscovich, Boaz Nadler, Clifford Spiegelman (2014)
                    <a href="berkjones/CKS_poster.pdf"><b>Tail sensitive Goodness-of-fit</b></a>,
                    Poster presentation at the spring school "Structural Inference in Statistics: Adaptation and Efficiency". (somewhat outdated)
                </p>
                <img src="img/rare_weak_misdetection_leader_n1000.png" class="img-rounded" style="width: 50%; margin-left: auto; margin-right: auto;">
                <img src="img/normal_scaling_ks_vs_ad_vs_mn_n100.svg" class="img-rounded" style="width: 47.4%; margin-left: auto; margin-right: auto;">
                <br>
                <br>
                <br>
                <br>
                <h4> Code </h4>
                <p>
                    <b>Code for computing exact Berk-Jones statistic:</b>
                    <a href="berkjones/exact_berk_jones.py">Python</a>, <a href="berkjones/exact_berk_jones.R">R</a>
                </p>
                <p>
                For computing the p-value of the M<sub>n</sub>, M<sub>n</sub><sup>+</sup> and M<sub>n</sub><sup>-</sup> statistics, see the <a class="page-scroll" href="#crossprob">Boundary Crossing</a> section.
                </p>
                <p>
                    Code that reproduces all of the figures in the paper: <a href="berkjones/exact_bj_paper_produce_figures.zip">exact_bj_paper_produce_figures.zip</a>
                </p>
            </div>
        </div>
    </section>

    <section id="crossprob" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h1>Boundary crossing</h1>
                <p>
                    Consider a one-dimensional homogeneous <a href="https://en.wikipedia.org/wiki/Poisson_point_process#Defined_on_the_real_line">Poisson process</a>.
                    Given arbitrary boundary functions from above and below, how can we compute the boundary crossing probability
                    of this process?
                    This problem has several applications in statistics, including the computation of exact p-values and power for supremum-based continuous goodness-of-fit statistics, such as Kolmogorov-Smirnov, Berk-Jones and others.
                </p>
                <img src="img/crossprob-illustration.svg" class="img-rounded" style="width: 70%; height: auto; margin-left: auto; margin-right: auto; display: block"><br><br>
                <p>
                    Despite more than 50 years of research, the most efficient practical methods to date 
                    compute this probability in O(n^3) time, where <b>n</b> is an upper bound on the boundary functions.
                    In this work, we discovered a simple and practical algorithm for this problem that solves it in O(n^2 log n) and more complicated O(n^2) algorithms, both for the one-sided and two-sided problem.
                </p>
                <h4> Documents </h4>
                <p>
                Amit Moscovich, Boaz Nadler <a href="https://arxiv.org/abs/1503.04363"><b>Fast calculation of boundary crossing probabilities for Poisson processes</b></a>, Statistics & Probability letters (2016), <b>in press</b>. <br>
                </p>
                <p>
                    Amit Moscovich, Boaz Nadler, <b>Faster calculation of boundary crossing probabilities for Poisson processes</b>, in preparation. <br>
                </p>

                <p>
                    Amit Moscovich, Boaz Nadler (2015) 
                    <a href="crossprob/crossing_probability_poster_mlss2015.pdf"><b>Fast computation of boundary crossing
probabilities for the empirical CDF</b></a>, poster+oral presentation at the Machine Learning Summer School in Kyoto.
                </p>
                <h4> Code </h4>
                <p>
                    A fast C++ implementation of several fast algorithms discussed in these papers:
                    <a href="https://github.com/mosco/crossing-probability">crossing-probability</a>
                </p>
            </div>
        </div>
    </section>

    <section id="forestdensity" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h1>Nonparametric classification of forest-structured graphical models</h1>
                <p>
                We propose a new nonparametric approach for binary classification that exploits the modeling flexibility of sparse graphical models. We assume that each class can be represented by a family of undirected sparse graphical models, specifically a forest-structured distribution. Our procedure requires the nonparametric estimation of only one and two-dimensional marginal densities to transform the data into a space where a linear classifier is optimal. Experiments with simulated and real data indicate that the proposed method is competitive with popular methods across a range of applications.
                </p>
                <p>
                    Joint work with Mary Frances Dorn and Clifford Spiegelman of Texas A&amp;M university and Boaz Nadler of the Weizmann institute of science.
                </p>
                <p>
                    <b>Paper in preparation.</b>
                </p>
            </div>
        </div>
    </section>


    <!-- Footer -->
    <footer>
        <div class="container text-center">
            Page design based on the <a href="http://startbootstrap.com/template-overviews/grayscale/">Grayscale</a> bootstrap theme.
            Background image by Ted Eytan. (CC BY-SA 2.0)
        </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Google Maps API Key - Use your own API key to enable the map feature. More information on the Google Maps API can be found at https://developers.google.com/maps/ -->
    <script type="text/javascript" src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCRngKslUGJTlibkQ3FkfTxj3Xss1UlZDA&sensor=false"></script>

    <!-- Theme JavaScript -->
    <script src="js/grayscale.min.js"></script>

</body>

</html>
